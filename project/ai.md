Artificial Intelligence (AI) usage, policy & co


# Policy

* own policy
* Acceptable Use Policy
* Data classification requirement
  * not for confidential+ data/suppose good classification but in practice, often global button

# Local or Cloud

# Incidents

# References

* Example policy: https://github.com/ThalesGroup/secure-ml/blob/main/security-policy/ml-secpol.md, https://github.com/ThalesGroup/secure-ml/blob/main/security-policy/ml-secpol-detailed.md

* [AI Risk Repository, MIT](https://airisk.mit.edu)
* [Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems, Jan 2024](https://arxiv.org/html/2401.05778v1)
* [Periodic Table of (Gen)AI Risks a quick reference, Feb 2025](https://www.linkedin.com/posts/iryna-schwindt-463a20158_every-day-we-see-hundreds-of-posts-highlighting-activity-7289375956509548544-7oBw)

News
* [Majority of firms using generative AI experience related security incidents ‚Äì even as it empowers security teams, Nov 2024](https://www.itpro.com/technology/artificial-intelligence/majority-firms-using-generative-ai-related-security-incidents): "[Research](https://www.capgemini.com/insights/research-library/generative-ai-in-cybersecurity) by the Capgemini Research Institute found that 97% of organizations using generative AI were affected by data breaches or security concerns linked to generative AI. Over half (52%) pointed to direct and indirect losses of at least $50 million arising from these incidents. As a result, nearly six in ten (62%) said they needed to increase their budgets to mitigate the risks."
* [AI adoption in business is lagging really far behind the buzz. Only 5% of American companies actively use AI in their products, and for many startups, profitability is still a distant goal (if even reachable).](https://www.linkedin.com/feed/update/urn:li:activity:7264672924890984449/), [Will the bubble burst for AI in 2025, or will it start to deliver?It is the biggest gamble in business history‚Äîbut adoption of AI is proving patchy, Nov 2024](https://www.economist.com/the-world-ahead/2024/11/18/will-the-bubble-burst-for-ai-in-2025-or-will-it-start-to-deliver)
* [The images of Spain‚Äôs floods weren‚Äôt created by AI. The trouble is, people think they were, Nov 2024](https://www.theguardian.com/commentisfree/2024/nov/09/the-images-of-spains-floods-werent-created-by-ai-the-trouble-is-people-think-they-were)
* [This can‚Äôt be real. While organizations are busy enforcing AI policies to protect confidential data, Microsoft quietly enables this by default and labels it ‚ÄòYour privacy matters.‚Äô Unbelievable. Nov 2024](https://x.com/cyb3rops/status/1860604009767145776): "Heads up: Microsoft Office, like many companies in recent months, has slyly turned on an ‚Äúopt-out‚Äù feature that scrapes your Word and Excel documents to train its internal AI systems. This setting is turned on by default, and you have to manually uncheck a box in order to opt out.  If you are a writer who uses MS Word to write any proprietary content (blog posts, novels, or any work you intend to protect with copyright and/or sell), you‚Äôre going to want to turn this feature off immediately."
* [German-French recommendations for the use of AI programming assistants, Oct 2024](https://www.bsi.bund.de/SharedDocs/Downloads/EN/BSI/KI/ANSSI_BSI_AI_Coding_Assistants.html), [L‚ÄôANSSI et le BSI publient leurs recommandations de s√©curit√© concernant les assistants de programmation bas√©s sur l‚ÄôIA, Oct 2024](https://cyber.gouv.fr/actualites/lanssi-et-le-bsi-publient-leurs-recommandations-de-securite-concernant-les-assistants-de)
* [OpenAI‚Äôs transcription software, Whisper, ‚Äúis prone to making up chunks of text or even entire sentences‚Äù of which ‚Äúsome of the invented text ‚Äî known in the industry as hallucinations ‚Äî can include racial commentary, violent rhetoric and even imagined medical treatments.‚Äù, Oct 2024](https://www.linkedin.com/feed/update/urn:li:activity:7256619287316967425/), https://www.pcmag.com/news/openais-whisper-experiencing-ai-hallucinations-despite-high-risk-applications
* [A great article in ACM on why humans and machines are different in terms of contextualization. They don‚Äôt even talk about consciousness. Nov 2024](https://www.linkedin.com/posts/pannala_the-context-problem-in-artificial-intelligence-activity-7265323181584900097-eeeV/), https://cacm.acm.org/opinion/the-context-problem-in-artificial-intelligence/
* [New Case Study in AI Risk Quantification: FAIR-AIR  Supporting Dissent in the FTC‚Äôs Rytr Case, Nov 2024](https://www.fairinstitute.org/blog/ai-risk-quantification-case-study-fair-air-ftc-rytr-case)
* [Industry trends Zero Trust 4 min read Agile Business, agile security: How AI and Zero Trust work together, Dec 2024](https://www.microsoft.com/en-us/security/blog/2024/12/16/agile-business-agile-security-how-ai-and-zero-trust-work-together/)
* [Fast vs. Slow AI, Jan 2025](https://danielmiessler.com/blog/fast-vs-slow-ai): We need to know when to use vs. refuse AI's speed
* [Implementing responsible AI in the generative age, Jan 2025](https://www.technologyreview.com/2025/01/22/1110043/implementing-responsible-ai-in-the-generative-age/) (report register-wall)
* [The Impact of Generative AI on Critical Thinking: Self-Reported Reductions in Cognitive Effort and Confidence Effects From a Survey of Knowledge Workers, Jan 2025](https://www.microsoft.com/en-us/research/uploads/prod/2025/01/lee_2025_ai_critical_thinking_survey.pdf), [GenAI is reshaping work‚Äîdon‚Äôt let it dull human intelligence, Jan 2025](https://www.hfsresearch.com/research/genai-reshaping-work-intelligence/)
* [AI Cybersecurity Collaboration Playbook, Jan 2025](https://www.cisa.gov/resources-tools/resources/ai-cybersecurity-collaboration-playbook), [JCDC's AI Cybersecurity Playbook](lockboxx.blogspot.com/2025/01/jcdcs-ai-cybersecurity-playbook.html)
* [AI Copilot Code Quality: 2025 Look Back at 12 Months of Data, Feb 2025](https://www.gitclear.com/ai_assistant_code_quality_2025_research): Emerging trends: 4x more code cloning, "copy/paste" exceeds "moved" code for first time in history. Includes 2025 projections.
* [How to Steer AI Adoption: A CISO Guide, Feb 2025](https://thehackernews.com/2025/02/how-to-steer-ai-adoption-ciso-guide.html): CLEAR 5 steps, Create, Learn, Enforce, Apply, Reuse
* [Disrupting malicious uses of AI, Feb 2025](https://openai.com/global-affairs/disrupting-malicious-uses-of-ai/) - China, Visibility




Videos
* [The existential horror of the paperclip factory. Oct 2024](https://www.youtube.com/watch?v=ZP7T6WAK3Ow) - French, English subtitles: Alignment, deception. https://www.securite-ia.fr/
* [Writing Doom ‚Äì Award-Winning Short Film on Superintelligence (2024), Oct 2024](https://www.youtube.com/watch?v=xfMQ7hzyFW4), https://futureoflife.org/project/superintelligence-imagined/


Navigating 4 stages of Cloud Privacy for AI and ML Strategies, email+web
https://www.microsoft.com/en-us/security/blog/2021/12/09/best-practices-for-ai-security-risk-management/
https://github.com/mitre/advmlthreatmatrix
https://www.nist.gov/itl/ai-risk-management-framework
https://www.cisa.gov/news-events/alerts/2024/04/15/joint-guidance-deploying-ai-systems-securely
https://www.enisa.europa.eu/publications/cybersecurity-of-ai-and-standardisation
https://www.enisa.europa.eu/topics/iot-and-smart-infrastructures/artificial_intelligence/?tab=publications
https://www.forbes.com/councils/forbestechcouncil/2023/12/27/ai-in-security-policies-why-its-important-and-how-to-implement/
https://www.trendmicro.com/en_us/ciso/23/f/ai-cybersecurity-policy-considerations.html
https://blog.google/technology/safety-security/introducing-googles-secure-ai-framework/
https://owasp.org/www-project-top-10-for-large-language-model-applications/¬†
https://www.linkedin.com/posts/jalkove_enterprises-are-quickly-learning-that-ai-activity-7252738782158835714-RNV5?
    https://x.com/Benioff/status/1846985572553830850 "When you look at how Copilot has been delivered to customers, it‚Äôs disappointing. It just doesn‚Äôt work, and it doesn‚Äôt deliver any level of accuracy. Gartner says it‚Äôs spilling data everywhere, and customers are left cleaning up the mess. To add insult to injury, customers are then told to build their own custom LLMs. I have yet to find anyone who‚Äôs had a transformational experience with Microsoft Copilot or the pursuit of training and retraining custom LLMs. Copilot is more like Clippy 2.0.ü§∑‚Äç‚ôÇÔ∏è#AI #Microsoft #Copilot https://www.fastcompany.com/91208578/why-marc-benioff-is-all-in-on-ai-agentforce"
    https://x.com/Benioff/status/1848439092293275988 "Microsoft rebranding Copilot as ‚Äòagents‚Äô? That‚Äôs panic mode. Let‚Äôs be real‚ÄîCopilot‚Äôs a flop because Microsoft lacks the data, metadata, and enterprise security models to create real corporate intelligence. That is why Copilot is inaccurate, spills corporate data, and forces customers to build their own LLMs. Clippy 2.0, anyone? Meanwhile, Agentforce is transforming businesses now. Agentforce doesn‚Äôt just handle tasks‚Äîit autonomously drives sales, service, marketing, analytics, and commerce. With data, LLMs, workflows, and security all integrated into a single Customer 360 platform: This is what AI was meant to be. ‚ù§Ô∏èü§ñ #Agentforce #Customer360"
    https://huggingface.co/datasets/Salesforce/ContextualBench

AI Tokens/words limits: 512 to 4096, GPT4 32k, Claude2 100k, Gemini 1.5 Pro 1M
https://www.supernormal.com/blog/gpt-token-limits
https://www.linkedin.com/pulse/what-llm-token-limits-comparative-analysis-top-large-language-mohan
https://medium.com/@jaimonjk/how-can-large-token-limits-in-new-llm-models-transform-the-learning-and-development-function-5fc643c8df0d
https://www.bretcameron.com/blog/three-strategies-to-overcome-open-ai-token-limits
