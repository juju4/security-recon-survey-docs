Artificial Intelligence (AI) usage, policy & co

# AI/ML Governance Strategy
Define your purpose: trust, explainability, compliance...
Ask: What models are we building? Who owns the risks? What‚Äôs our stance on LLMs or autonomous systems?
Set your risk appetite and responsible AI principles.

# Policy

* own policy
* Acceptable Use Policy
* Data classification requirement
  * not for confidential+ data/suppose good classification but in practice, often global button
* Roles and Model Lifecycle Ownership

# Local or Cloud

# Incidents

# References

* Example policy: https://github.com/ThalesGroup/secure-ml/blob/main/security-policy/ml-secpol.md, https://github.com/ThalesGroup/secure-ml/blob/main/security-policy/ml-secpol-detailed.md

* [NIST AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework)
* [ISO/IEC 42001:2023 Information technology ‚Äî Artificial intelligence ‚Äî Management system](https://www.iso.org/standard/81230.html)
* [AI Risk Repository, MIT](https://airisk.mit.edu)
* [Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems, Jan 2024](https://arxiv.org/html/2401.05778v1)
* [Periodic Table of (Gen)AI Risks a quick reference, Feb 2025](https://www.linkedin.com/posts/iryna-schwindt-463a20158_every-day-we-see-hundreds-of-posts-highlighting-activity-7289375956509548544-7oBw)
* [AI Incident Database](https://incidentdatabase.ai/)
* [Global AI Regulation Tracker](https://www.techieray.com/GlobalAIRegulationTracker)
* https://www.sans.org/mlp/critical-ai-security-guidelines
* [OWASP AI Testing Guide](https://github.com/OWASP/www-project-ai-testing-guide/tree/main/Document)
* [From bugs to bypasses: adapting vulnerability disclosure for AI safeguards, Sep 2025](https://www.ncsc.gov.uk/blog-post/from-bugs-to-bypasses-adapting-vulnerability-disclosure-for-ai-safeguards)
* [Intelligence Artificielle : les travaux de l‚ÄôANSSI](https://cyber.gouv.fr/intelligence-artificielle-les-travaux-de-lanssi)

News
* [Majority of firms using generative AI experience related security incidents ‚Äì even as it empowers security teams, Nov 2024](https://www.itpro.com/technology/artificial-intelligence/majority-firms-using-generative-ai-related-security-incidents): "[Research](https://www.capgemini.com/insights/research-library/generative-ai-in-cybersecurity) by the Capgemini Research Institute found that 97% of organizations using generative AI were affected by data breaches or security concerns linked to generative AI. Over half (52%) pointed to direct and indirect losses of at least $50 million arising from these incidents. As a result, nearly six in ten (62%) said they needed to increase their budgets to mitigate the risks."
* [AI adoption in business is lagging really far behind the buzz. Only 5% of American companies actively use AI in their products, and for many startups, profitability is still a distant goal (if even reachable).](https://www.linkedin.com/feed/update/urn:li:activity:7264672924890984449/), [Will the bubble burst for AI in 2025, or will it start to deliver?It is the biggest gamble in business history‚Äîbut adoption of AI is proving patchy, Nov 2024](https://www.economist.com/the-world-ahead/2024/11/18/will-the-bubble-burst-for-ai-in-2025-or-will-it-start-to-deliver)
* [The images of Spain‚Äôs floods weren‚Äôt created by AI. The trouble is, people think they were, Nov 2024](https://www.theguardian.com/commentisfree/2024/nov/09/the-images-of-spains-floods-werent-created-by-ai-the-trouble-is-people-think-they-were)
* [This can‚Äôt be real. While organizations are busy enforcing AI policies to protect confidential data, Microsoft quietly enables this by default and labels it ‚ÄòYour privacy matters.‚Äô Unbelievable. Nov 2024](https://x.com/cyb3rops/status/1860604009767145776): "Heads up: Microsoft Office, like many companies in recent months, has slyly turned on an ‚Äúopt-out‚Äù feature that scrapes your Word and Excel documents to train its internal AI systems. This setting is turned on by default, and you have to manually uncheck a box in order to opt out.  If you are a writer who uses MS Word to write any proprietary content (blog posts, novels, or any work you intend to protect with copyright and/or sell), you‚Äôre going to want to turn this feature off immediately."
* [German-French recommendations for the use of AI programming assistants, Oct 2024](https://www.bsi.bund.de/SharedDocs/Downloads/EN/BSI/KI/ANSSI_BSI_AI_Coding_Assistants.html), [L‚ÄôANSSI et le BSI publient leurs recommandations de s√©curit√© concernant les assistants de programmation bas√©s sur l‚ÄôIA, Oct 2024](https://cyber.gouv.fr/actualites/lanssi-et-le-bsi-publient-leurs-recommandations-de-securite-concernant-les-assistants-de)
* [OpenAI‚Äôs transcription software, Whisper, ‚Äúis prone to making up chunks of text or even entire sentences‚Äù of which ‚Äúsome of the invented text ‚Äî known in the industry as hallucinations ‚Äî can include racial commentary, violent rhetoric and even imagined medical treatments.‚Äù, Oct 2024](https://www.linkedin.com/feed/update/urn:li:activity:7256619287316967425/), https://www.pcmag.com/news/openais-whisper-experiencing-ai-hallucinations-despite-high-risk-applications
* [A great article in ACM on why humans and machines are different in terms of contextualization. They don‚Äôt even talk about consciousness. Nov 2024](https://www.linkedin.com/posts/pannala_the-context-problem-in-artificial-intelligence-activity-7265323181584900097-eeeV/), https://cacm.acm.org/opinion/the-context-problem-in-artificial-intelligence/
* [New Case Study in AI Risk Quantification: FAIR-AIR  Supporting Dissent in the FTC‚Äôs Rytr Case, Nov 2024](https://www.fairinstitute.org/blog/ai-risk-quantification-case-study-fair-air-ftc-rytr-case)
* [Industry trends Zero Trust 4 min read Agile Business, agile security: How AI and Zero Trust work together, Dec 2024](https://www.microsoft.com/en-us/security/blog/2024/12/16/agile-business-agile-security-how-ai-and-zero-trust-work-together/)
* [Fast vs. Slow AI, Jan 2025](https://danielmiessler.com/blog/fast-vs-slow-ai): We need to know when to use vs. refuse AI's speed
* [Implementing responsible AI in the generative age, Jan 2025](https://www.technologyreview.com/2025/01/22/1110043/implementing-responsible-ai-in-the-generative-age/) (report register-wall)
* [The Impact of Generative AI on Critical Thinking: Self-Reported Reductions in Cognitive Effort and Confidence Effects From a Survey of Knowledge Workers, Jan 2025](https://www.microsoft.com/en-us/research/uploads/prod/2025/01/lee_2025_ai_critical_thinking_survey.pdf), [GenAI is reshaping work‚Äîdon‚Äôt let it dull human intelligence, Jan 2025](https://www.hfsresearch.com/research/genai-reshaping-work-intelligence/)
* [AI Cybersecurity Collaboration Playbook, Jan 2025](https://www.cisa.gov/resources-tools/resources/ai-cybersecurity-collaboration-playbook), [JCDC's AI Cybersecurity Playbook](lockboxx.blogspot.com/2025/01/jcdcs-ai-cybersecurity-playbook.html)
* [AI Copilot Code Quality: 2025 Look Back at 12 Months of Data, Feb 2025](https://www.gitclear.com/ai_assistant_code_quality_2025_research): Emerging trends: 4x more code cloning, "copy/paste" exceeds "moved" code for first time in history. Includes 2025 projections.
* [How to Steer AI Adoption: A CISO Guide, Feb 2025](https://thehackernews.com/2025/02/how-to-steer-ai-adoption-ciso-guide.html): CLEAR 5 steps, Create, Learn, Enforce, Apply, Reuse
* [Disrupting malicious uses of AI, Feb 2025](https://openai.com/global-affairs/disrupting-malicious-uses-of-ai/) - China, Visibility
* [Thomson Reuters Wins First Major AI Copyright Case in the US, Feb 2025](https://www.wired.com/story/thomson-reuters-ai-copyright-lawsuit/)
* [Microsoft‚Äôs Satya Nadella Pumps the Brakes on AI Hype, Feb 2025](https://gizmodo.com/microsofts-satya-nadella-pumps-the-breaks-on-ai-hype-2000566483)
* [AI Search Has A Citation Problem, Mar 2025](https://www.cjr.org/tow_center/we-compared-eight-ai-search-engines-theyre-all-bad-at-citing-news.php)
* [AI can steal your voice, and there's not much you can do about it, Mar 2025](https://www.nbcnews.com/tech/security/ai-voice-cloning-software-flimsy-guardrails-report-finds-rcna195131)
* [Klarna CEO doubts that other companies will replace Salesforce with AI, Mar 2025](https://techcrunch.com/2025/03/04/klarna-ceo-doubts-that-other-companies-will-replace-salesforce-with-ai/)
* [OpenAI declares AI race ‚Äúover‚Äù if training on copyrighted works isn‚Äôt fair use, Mar 2025](https://arstechnica.com/tech-policy/2025/03/openai-urges-trump-either-settle-ai-copyright-debate-or-lose-ai-race-to-china/)
* [Anyone has Microsoft Security Copilot in place? Mar 2025](https://www.reddit.com/r/cybersecurity/comments/1jcw9x3/anyone_has_microsoft_security_copilot_in_place/)
* [AI project failure rates are on the rise: report. The share of businesses scrapping most of their AI initiatives increased to 42% this year, up from 17% last year, according to S&P Global Market Intelligence. Mar 2025](https://www.cybersecuritydive.com/news/AI-project-fail-data-SPGlobal/742768/)
* [Singapore authorities warn of rise in deepfake corporate video calls, Mar 2025](https://www.finextra.com/newsarticle/45645/singapore-authorities-warn-of-rise-in-deepfake-corporate-video-calls)
* [Study Finds That AI Search Engines Are Wrong an Astounding Proportion of the Time, Mar 2025](https://futurism.com/study-ai-search-wrong)
* [Implementation guide for managers of Artificial intelligence systems - ISDE Canada](https://ised-isde.canada.ca/site/ised/en/implementation-guide-managers-artificial-intelligence-systems)
* [CJEU Delivers Judgment on Automated Decision-Making, Mar 2025](https://www.griffinhouseconsultancy.co.uk/blog/cjeu-delivers-judgment-on-automated-decision-making/) - Schufa AG credit score, Case C-634-21
* [10 things you should include in your AI policy, Apr 2025](https://www.csoonline.com/article/3950176/10-things-you-should-include-in-your-ai-policy.html)
* [AI-hallucinated code dependencies become new supply chain risk, Apr 2025](https://www.bleepingcomputer.com/news/security/ai-hallucinated-code-dependencies-become-new-supply-chain-risk/)
* [AI 2027](https://ai-2027.com) AGI scenario
* [Professors Staffed a Fake Company Entirely With AI Agents, and You'll Never Guess What Happened, Apr 2025](https://futurism.com/professors-company-ai-agents), [Carnegie Mellon staffed a fake company with AI agents. It was a total disaster.](https://tech.yahoo.com/ai/articles/next-assignment-babysitting-ai-081502817.html?guccounter=1), https://the-agent-company.com/
* [OpenAI Stirs Controversy with GPT-4.1 Release Lacking Safety Report!, Apr 2025](https://opentools.ai/news/openai-stirs-controversy-with-gpt-41-release-lacking-safety-report)
* [New ChatGPT Models Seem to Leave Watermarks on Text, Apr 2025](https://www.rumidocs.com/newsroom/new-chatgpt-models-seem-to-leave-watermarks-on-text)
* [How to even get started with AI governance? Apr 2025](https://www.linkedin.com/posts/gregoryhaardt_how-to-even-get-started-with-ai-governance-activity-7319797388410265600-jq-t)
* [Superintelligent AgentsPose Catastrophic Risks:Can Scientist AI Offer aSafer Path? Yoshua Bengio, MILA, Apr 2025](https://indico.cern.ch/event/1522388/attachments/3044597/5380129/CERN-3apr2025.pdf)
* [CrowdStrike Research: Securing AI-Generated Code with Multiple Self-Learning AI Agents, Apr 2025](https://www.crowdstrike.com/en-us/blog/secure-ai-generated-code-with-multiple-self-learning-ai-agents/)
* [Your future AI Assistant still needs to earn your trust, Apr 2025. The next generation of AI Assistants may seek extensive access to our personal data, accounts and devices features. Can we trust their developers to protect our privacy and security?](https://privacyinternational.org/long-read/5555/your-future-ai-assistant-still-needs-earn-your-trust)
* [Reality Check](https://www.wheresyoured.at/reality-check/) - OpenAI Revenues
* [Time saved by AI offset by new work created, study suggests. Survey of 2023‚Äì2024 data finds that AI created more tasks for 8.4 percent of workers. May 2025](https://arstechnica.com/ai/2025/05/time-saved-by-ai-offset-by-new-work-created-study-suggests/)
* [Large Language Models are Unreliable for Cyber Threat Intelligence, Mar 2025](https://arxiv.org/abs/2503.23175)
* [Lessons from Defending Gemini Against Indirect Prompt Injections, May 2025](https://arxiv.org/abs/2505.14534v1)
* [This comes across as just a tiiiny little bit customer hostile. - Copilot](https://bsky.app/profile/getwired.com/post/3lpmraracqk2f)
* [Busting myths on Microsoft Security Copilot, May 2025](https://techcommunity.microsoft.com/blog/securitycopilotblog/busting-myths-on-microsoft-security-copilot/4414844)* [If you want an lol - Microsoft have implemented Copilot on its own GitHub repos and it‚Äôs a clusterfuck, you can see MS engineers publicly begging Copilot to work.www.reddit.com/r/Experience...](https://bsky.app/profile/GossiTheDog.cyberplace.social.ap.brid.gy/post/3lpor3uglie22), [My new hobby: watching AI slowly drive Microsoft employees insane, May 2025](https://www.reddit.com/r/ExperiencedDevs/comments/1krttqo/my_new_hobby_watching_ai_slowly_drive_microsoft/), [Allow us to block Copilot-generated issues (and PRs) from our own repositories #159749](https://github.com/orgs/community/discussions/159749)
* [Klarna decided it would lay off 700 of its workers and replace them with AI, with its CEO saying he would be ‚ÄúOpenAI‚Äôs guinea pig‚Äù.   He now says ‚Äú..what you end up having is lower quality,‚Äù.. and goes on to say he‚Äôs realised customers expect to able to talk to a customer support agent.   So he‚Äôs come up with a genius recovery  plan - hire human workers he fired to replace the AI bots he installed.  https://finance.yahoo.com/news/firing-700-humans-ai-klarna-173029838.html, May 2025](https://bsky.app/profile/GossiTheDog.cyberplace.social.ap.brid.gy/post/3lpmc25gvtny2)
* [The 2025 AI Index Report, May 2025](https://hai.stanford.edu/ai-index/2025-ai-index-report)
* [This is interesting, the newer LLM models are getting worse, as this article and associated research paper at https://lnkd.in/et3XT8Cg demonstrate. May 2025](https://www.linkedin.com/posts/richardselfllm_this-is-interesting-the-newer-llm-models-activity-7330013445070741505-_6cj), [Generalization bias in large language model summarization of scientific research, Apr 2025](https://royalsocietypublishing.org/doi/10.1098/rsos.241776)
* [Take Nature‚Äôs AI research test: find out how your ethics compareWhat‚Äôs your view on using AI for peer review and for writing research papers? May 2025](https://www.nature.com/immersive/d41586-025-01512-2/index.html)
* [Widely covered MIT paper saying AI boosts worker productivity is, in fact, complete bullshit it turns out.](https://bsky.app/profile/GossiTheDog.cyberplace.social.ap.brid.gy/post/3lpdzkc3eomy2), https://www.wsj.com/tech/ai/mit-says-it-no-longer-stands-behind-students-ai-research-paper-11434092?st=sF3Wvo&reflink=desktopwebshare_permalink
* [A computer scientist‚Äôs perspective on vibe coding:](https://bsky.app/profile/garymarcus.bsky.social/post/3lpdgtvi7k22d), https://bsky.app/profile/qntm.org/post/3lpbv23rz622c
* [Should We Automate the CEO? TheHustle, Mar 2023](https://getpocket.com/explore/item/should-we-automate-the-ceo), HK NetDragon Websoft
* [Secret chatbot use causes workplace rifts, May 2025](https://www.axios.com/2025/05/29/secret-chatgpt-workplace)
* [A new report from Stanford finds that schools, parents, police, and our legal system are not prepared to deal with the growing problem of minors using AI to generate CSAM of other minors.üîó https://www.404media.co/no-one-knows-how-to-deal-with-student-on-student-ai-csam/, May 2025](https://bsky.app/profile/404media.co/post/3lqcsi4tolk2l), https://cyber.fsi.stanford.edu/news/ai-csam-report
* [Duolingo's AI-First Disaster: A Cautionary Tale of What Happens When You Replace Rather Than Partner. Duolingo's 'AI-first' strategy backfired so badly they deleted all content from 6.7M TikTok and 4.1M Instagram accounts. The cautionary tale every CEO needs to read about replacing humans with AI. May 2025](https://www.groktop.us/duolingos-ai-first-disaster-a-cautionary-tale-of-what-happens-when-you-replace-rather-than-partner/)
* [shocked to hear that ‚Äú...AI chatbots have had no significant impact on earnings or recorded hours in any occupation" based on a study of 25,000 workers at 7000 companies by the National Bureau of Economic Research, May 2025](https://bsky.app/profile/edzitron.com/post/3lpujcx324k2m), https://www.nber.org/papers/w33777, https://fortune.com/2025/05/18/ai-chatbots-study-impact-earnings-hours-worked-any-occupation/
* ["A database attempting to track the prevalence of the cases has identified 106 instances around the globe in which courts have found 'AI hallucinations' in court documents."](https://www.damiencharlotin.com/hallucinations/)
* [Anthropic‚Äôs new AI model turns to blackmail when engineers try to take it offline, May 2025](https://techcrunch.com/2025/05/22/anthropics-new-ai-model-turns-to-blackmail-when-engineers-try-to-take-it-offline/)
* [RSA 2025: AI‚Äôs Promise vs. Security‚Äôs Past ‚Äî A Reality Check, May 2025](https://medium.com/anton-on-security/rsa-2025-ais-promise-vs-security-s-past-a-reality-check-e06deb3bd579)
* [AI doomers and AI zoomers are two sides of the same coin, powered by a quasi-supernatural belief that God is coming to the machine. The reality is more mundane: that semi-functional AIs will thoroughly undermine the existing social order through myriad systems of abuse. Jun 2025](https://bsky.app/profile/joegalvin.bsky.social/post/3lqpf4e5g6s2m) - deepfake nudes
* [Generative AI in the Law School Classroom, Jun 2025](https://jeremysheff.com/2025/06/02/generative-ai-in-the-law-school-classroom/)
* [My AI Skeptic Friends Are All Nuts, Jun 2025](https://fly.io/blog/youre-all-nuts/)
* [What 17,845 GitHub Repos Taught Us About Malicious MCP Servers, Jun 2025](https://blog.virustotal.com/2025/06/what-17845-github-repos-taught-us-about.html)
* [CDT Europe‚Äôs assessment of the AI Office‚Äôs guidelines on prohibited AI practices, Jun 2025](https://cdt.org/insights/cdt-europes-assessment-of-the-ai-offices-guidelines-on-prohibited-ai-practices/): Harmful manipulation and deception, Harmful exploitation of vulnerabilities, Social scoring, Individual criminal offense risk assessment and prediction, Untargeted scraping of facial images for facial recognition databases, Emotion recognition at the workplace or in education, Biometric categorisation systems, Biometric categorisation systems
* [Package Hallucinations: How LLMs Can Invent Vulnerabilities, Jun 2025](https://www.usenix.org/publications/loginonline/we-have-package-you-comprehensive-analysis-package-hallucinations-code)
* [Mike Lindell‚Äôs lawyers used AI to write brief‚Äîjudge finds nearly 30 mistakes, Apr 2025](https://arstechnica.com/tech-policy/2025/04/mypillow-ceos-lawyers-used-ai-in-brief-citing-fictional-cases-judge-says/) ‚ÄúA lawyer representing MyPillow and its CEO Mike Lindell in a defamation case admitted using artificial intelligence in a brief that has nearly 30 defective citations, including misquotes and citations to fictional cases, a federal judge said.‚Äù
* ["A computer can never be held accountable therefore a computer must never make a management decision"](https://bsky.app/profile/silascutler.bsky.social/post/3lrjgpist242w), IBM Training Manual, 1979, https://www.ibm.com/think/insights/ai-decision-making-where-do-businesses-draw-the-line
* [Exclusive: New Microsoft Copilot flaw signals broader risk of AI agents being hacked‚Äî‚ÄòI would be terrified‚Äô, Jun 2025](https://fortune.com/2025/06/11/microsoft-copilot-vulnerability-ai-agents-echoleak-hacking/)
* [How I use AI (2025), Jun 2025](https://blog.sshh.io/p/how-i-use-ai-2025)
* [The Ethical AI Bombshell That Just Blew Up Big Tech‚Äôs Biggest Lie, Jun 2025](https://www.linkedin.com/pulse/ethical-ai-bombshell-just-blew-up-big-techs-biggest-lie-dion-wiggins-qkgic) They said it was impossible. It wasn‚Äôt. Now the lie is dead, the theft behind the AI boom exposed‚Äîand Big AI is out of excuses, debunked by a ragtag team. The reckoning begins. https://blog.eleuther.ai/common-pile/
* [ChatGPT "Absolutely Wrecked" at Chess by Atari 2600 Console From 1977, Jun 2025](https://futurism.com/atari-beats-chatgpt-chess)
* [MCP Security Best Practices](https://modelcontextprotocol.io/specification/2025-06-18/basic/security_best_practices)
* [This Is What Happens When Hertz‚Äôs AI Scanner Finds Damage on Your Rental, Jun 2025](https://www.thedrive.com/news/this-is-what-happens-when-hertzs-ai-scanner-finds-damage-on-your-rental): One customer was charged $440 for a scuff on his rental's wheel. But talking to a human employee about it wasn't easy, and he was encouraged to pay ASAP.
* [Debating AI with Marcus Hutchins: Part 1, Jun 2025](https://www.youtube.com/watch?v=I9-iD_rLRjA) - Daniel Miessler, 2h
* [The r√©sum√© is dying, and AI is holding the smoking gun, Jun 2025](https://arstechnica.com/ai/2025/06/the-resume-is-dying-and-ai-is-holding-the-smoking-gun/)
* [AI Killed My Job: Tech workers, Jun 2025](https://www.bloodinthemachine.com/p/how-ai-is-killing-jobs-in-the-tech-f39): Tech workers at TikTok, Google, and across the industry share stories about how AI is changing, ruining, or replacing their jobs.
* [AUSCERT2025 - Generative AI Breaches: Threats, Investigations, and Response by Thomas Roccia, Jun 2025](https://www.youtube.com/watch?v=a_QBENR--nc)
* [The Danish government will clamp down on the creation and dissemination of AI-generated deepfakes by changing copyright law to ensure that everybody has the right to their own body, facial features and voice. Jun 2025](https://www.theguardian.com/technology/2025/jun/27/deepfakes-denmark-copyright-law-artificial-intelligence)
* [Google‚Äôs approach to AI Agents -- Threat Model Thursday, Jun 2025](https://shostack.org/blog/google-approach-to-ai-agents-threat-model-thursday/)
* [What The Workday Lawsuit Reveals About AI Bias‚ÄîAnd How To Prevent It, Jun 2025](https://www.forbes.com/sites/janicegassam/2025/06/23/what-the-workday-lawsuit-reveals-about-ai-bias-and-how-to-prevent-it/): discriminated against candidates 40 years old and over.
* [When ChatGPT summarises, it actually does nothing of the kind. May 2024](https://ea.rna.nl/2024/05/27/when-chatgpt-summarises-it-actually-does-nothing-of-the-kind/)
* [ACSE-Eval: Can LLMs threat model real-world cloud infrastructure? May 2025](https://arxiv.org/abs/2505.11565v2)
* [I‚Äôm Getting Real Tired Of Not Being Able To Trust That A Video Game Doesn‚Äôt Have AI Crap In It. It sucks that players are having to scour every asset and line of dialogue, Jun 2025](https://aftermath.site/the-alters-ai-controversy)
* [The Impact of Artificial Intelligence on the Cybersecurity Workforce, Jun 2025](https://www.nist.gov/blogs/cybersecurity-insights/impact-artificial-intelligence-cybersecurity-workforce)
* [Ciaran Martin: AI might disturb attacker-defender security balance, Jun 2025](https://www.computerweekly.com/news/366626443/Ciaran-Martin-AI-might-disturb-attacker-defender-security-balance)
* [First time a judge has decided a case based on hallucinated case law in the US that I've encountered. https://caselaw.findlaw.com/court/ga-court-of-appeals/117442275.html#:~:text=After%20the%20trial%20court%20entered%20a%20final%20judgment,an%20order%20that%20relied%20upon%20non-existent%20case%20law](https://bsky.app/profile/peterhenderson.bsky.social/post/3lt3ve6xa7k2i)
* [I‚Äôm losing all trust in the AI industry. It is facing many urgent problems that it‚Äôs not addressing. The list I share here is intended to spark conversation., Jul 2025](https://www.linkedin.com/posts/alberromgar_im-losing-all-trust-in-the-ai-industry-activity-7346613594504990721-iWhg?)
* [I spoke at Salesforce a few months ago and I heard one of the most brilliant things EVER ... by an attendee! Jul 2025](https://www.linkedin.com/posts/sol-rashidi-mba-a672291_futureofwork-workforce-ai-activity-7346534454359715843-GIDI?): 4D Evaluation, The Dangerous (dangerous tasks), The Dull (copy and paste), The Dirty (hazardous materials), The Difficult (massive data processing)
* [AI is porn for execs, and they're all drunk on it.  It's literally "look, you ask it to code something and it spits out all the code like The Matrix" is.. the entire thought process. It's even happening /inside/ Microsoft. Jul 2025](https://bsky.app/profile/doublepulsar.com/post/3ltaiez5r3s2b)
* [The Percentage of Tasks AI Agents Are Currently Failing At May Spell Trouble for the Industry, Jul 2025](https://futurism.com/ai-agents-failing-industry)
* ['I'm being paid to fix issues caused by AI', Jul 2025](https://www.bbc.com/news/articles/cyvm1dyp9v2o) "We often have to charge an investigation fee to find out what has gone wrong, as they don't want to admit it, and the process of correcting these mistakes takes much longer than if professionals had been consulted from the beginning."
* ['Positive review only': Researchers hide AI prompts in papers, Jul 2025](https://asia.nikkei.com/Business/Technology/Artificial-intelligence/Positive-review-only-Researchers-hide-AI-prompts-in-papers)
* [OpenAI tightens the screws on security to keep away prying eyes, Jul 2025](https://techcrunch.com/2025/07/07/openai-tightens-the-screws-on-security-to-keep-away-prying-eyes/)
* [As a developer, I find vibe coding fascinating. There's obviously a place for AI in programming, but vibe coding attracts hordes of non-developers trying to build companies. It seems reminiscent of "the ideas guy" fallacy. Jul 2025](https://www.linkedin.com/posts/malwaretech_as-a-developer-i-find-vibe-coding-fascinating-activity-7347803647486980096-pxfm?)
* [Your Brain on ChatGPT, Jun 2025](https://www.media.mit.edu/projects/your-brain-on-chatgpt/overview/): "Brain connectivity systematically scaled down with the amount of external support: the Brain‚Äëonly group exhibited the strongest, widest‚Äëranging networks, Search Engine group showed intermediate engagement, and LLM assistance elicited the weakest overall coupling", https://www.media.mit.edu/posts/your-brain-on-chatgpt-in-the-news/
* [A Copilot Studio Story 2: When AIjacking Leads to Full Data Exfiltration, Jul 2025](https://labs.zenity.io/p/a-copilot-studio-story-2-when-aijacking-leads-to-full-data-exfiltration-bc4a)
* [Companies That Tried to Save Money With AI Are Now Spending a Fortune Hiring People to Fix Its Mistakes, Jul 2025](https://futurism.com/companies-fixing-ai-replacement-mistakes)
* [I‚Äôm in a WhatsApp group for Security Copilot with business execs and pattern for months has been exec joins during pilot kickoff, says Security Copilot is amazing, then comes back a month later and asks if anybody knows how to optimize it, then reappears two months later asking how to justify it üòÖ Jul 2025](https://bsky.app/profile/doublepulsar.com/post/3ltn5yyxrdk2i)
* [AI voice clones have hit the White House AGAIN, now impersonating the Secretary of State to other Gov officials to try to steal secrets/access.
Here is a video of me live demoing how quick (2 min) and easy it is to clone a voice to hack and how to catch AI voice clone attacks in action! Jul 2025](https://bsky.app/profile/racheltobac.bsky.social/post/3lthzfrbvj22l), [Someone using AI to impersonate Marco Rubio contacted at least five people including foreign ministers, cable says, Jul 2025](https://www.cnn.com/2025/07/08/politics/marco-rubio-artificial-intelligence-impersonation)

* [From chatbots to adbots: sharing your thoughts with advertisers, Nov 2024](https://privacyinternational.org/long-read/5472/chatbots-adbots-sharing-your-thoughts-advertisers)
* [Bank forced to rehire workers after lying about chatbot productivity, union says, AU, Aug 2025](https://arstechnica.com/tech-policy/2025/08/bank-forced-to-rehire-workers-after-lying-about-chatbot-productivity-union-says/)
* [AI crawlers and fetchers are blowing up websites, with Meta and OpenAI the worst offenders, Aug 2025](https://www.theregister.com/2025/08/21/ai_crawler_traffic/): "One fetcher bot seen smacking a website with 39,000 requests per minute"
* [LLMs + Coding Agents = Security Nightmare, Aug 2025](https://garymarcus.substack.com/p/llms-coding-agents-security-nightmare)
* [Study finds 95% of AI pilot projects failed to generate significant revenue, Aug 2025](https://boingboing.net/2025/08/19/study-finds-95-of-ai-pilot-projects-failed-to-generate-significant-revenue.html), [MIT report: 95% of generative AI pilots at companies are failing, Aug 2025](https://fortune.com/2025/08/18/mit-report-95-percent-generative-ai-pilots-at-companies-failing-cfo/)
* [Microsoft Excel adds Copilot AI to help fill in spreadsheet cells, Aug 2025](https://www.theverge.com/news/761338/microsoft-excel-ai-copilot-spreadsheet-cell-filling): "Microsoft also warns against using the AI function for numerical calculations or in ‚Äúhigh-stakes scenarios‚Äù with legal, regulatory, and compliance implications, as COPILOT ‚Äúcan give incorrect responses.‚Äù"
* [Zscaler CEO just announced on a live event that they're using their 500 billion daily customer logs to train AI. Aug 2025](https://www.linkedin.com/posts/steven-swift-5238956a_zscaler-ceo-just-announced-on-a-live-event-activity-7363611171121238016-zRmv/), [Transcript from Zscaler's 2024 earning call](https://www.fool.com/earnings/call-transcripts/2024/09/03/zscaler-zs-q4-2024-earnings-call-transcript/)
* [AI Is a Mass-Delusion Event Three years in, one of AI‚Äôs enduring impacts is to make people feel like they‚Äôre losing it. Aug 2025](https://www.theatlantic.com/technology/archive/2025/08/ai-mass-delusion-event/683909/?gift=bQgJMMVzeo8RHHcE1_KM0Yxw_pOVM_AK6Q1K5aHOCSs)
* [Escalation Risks from AI in Military and Diplomatic Decision-Making, Aug 2025](https://www.isrs.ngo/fpb/escalation-risks-from-ai-in-military-and-diplomatic-decision-making)
* [Grok Exposes Underlying Prompts for Its AI Personas: ‚ÄòEVEN PUTTING THINGS IN YOUR ASS‚Äô, Aug 2025](https://www.404media.co/grok-exposes-underlying-prompts-for-its-ai-personas-even-putting-things-in-your-ass/)
* [WeTransfer just changed their ToS to allow them to train AI on any files you transfer through them.
Don't use there service, especially for work that you don't have the right to relicense to them (e.g., commercial work that's exactly the most likely to create the huge files WeTransfer specializes in). (ETA: this is already going boom so I'm muting it.) Jul 2025](https://io.mwl.io/@mwl/114854651817790706), [WeTransfer Backtracks on AI File Training After Backlash: What You Need to Know, Jul 2025](https://www.cnet.com/tech/services-and-software/wetransfer-backtracks-on-ai-file-training-after-backlash-what-you-need-to-know/)
* [Hugging Face is now hosting 5,000 AI image generation models of real people that were banned from Civitai due to pressure from payment processors. The company is not responding to requests for comment or showing interest in seeing this data. Jul 2025](https://www.404media.co/hugging-face-is-hosting-5-000-nonconsensual-ai-models-of-real-people/)
* [Interesting new research on a zero-click vulnerability in Microsoft Copilot that shows how AI models can be silently hacked to exfiltrate confidential data. Jul 2025](https://www.trendmicro.com/en_us/research/25/g/preventing-zero-click-ai-threats-insights-from-echoleak.html)
* [Fantastic paper from METR on the true impact of gen AI on development time. This study shows that experienced developers are less productive when using generative models than not. Specifically, on complex projects and ones in which they are experts. https://arxiv.org/pdf/2507.09089 Jul 2025](https://bsky.app/profile/taggart-tech.com/post/3ltzj36t5np2v), [Measuring the Impact of Early-2025 AI on Experienced Open-Source Developer Productivity, Jul 2025](https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/)
* [Introducing the CSA AI Controls Matrix: A Comprehensive Framework for Trustworthy AI, Jul 2025](https://cloudsecurityalliance.org/blog/2025/07/10/introducing-the-csa-ai-controls-matrix-a-comprehensive-framework-for-trustworthy-ai)
* [rsyslog Goes AI First ‚Äî A New Chapter Begins, Jul 2025](https://www.rsyslog.com/rsyslog-goes-ai-first-a-new-chapter-begins/), [Clarifying ‚ÄúAI First‚Äù ‚Äì What It Really Means for rsyslog, Jul 2025](https://www.rsyslog.com/clarifying-ai-first-what-it-really-means-for-rsyslog/): "embracing AI First (Human-Controlled)... AI is a collaborative partner, not an autonomous actor."
* [OpenAI Says It's Hired a Forensic Psychiatrist as Its Users Keep Sliding Into Mental Health Crises, Jul 2025](https://futurism.com/openai-forensic-psychiatrist)
* [The AI SOC Market Landscape 2025, Aug 2025](https://softwareanalyst.io/reports/ai-soc-industry-wide-report-2025/)
* [More Than 100 Hikers Have Died in Italy This Summer. What the Heck Is Going on? Aug 2025](https://www.outsideonline.com/outdoor-adventure/hiking-and-backpacking/italian-alps-deaths/): "‚ÄúSince about one year ago, many people have begun to think everything on ChatGPT is correct,‚Äù Vallata said. ‚ÄúIt is not a tool for mountain advice, for routes, or for planning.‚Äù"
* [Humans are being hired to make AI slop look less sloppy, Aug 2025. In the age of automation, human workers are being brought in to fix what artificial intelligence gets wrong.](https://www.nbcnews.com/tech/tech-news/humans-hired-to-fix-ai-slop-rcna225969)
* [How This A.I. Company Collapsed Amid Silicon Valley‚Äôs Biggest Boom, Aug 2025. Builder.ai went from a value of $1.5 billion to zero in a few months, amid questions over the sales of an A.I. product. Its downfall hints at a broader downturn.](https://www.nytimes.com/2025/08/31/technology/builder-ai-collapse.html)
* [The experience of the analyst in an AI-powered present, Aug 2025](https://jvehent.org/2025/08/30/The-experience-of-the-analyst-in-an-AI-powered-present.html)
* [VXUG dropped the news that a DEFCON talk was AI generated nonsense and so was the code put on github for it. Some attendees noticed it was off, but this talk was presented, passed review. The github issues are rolling in.](https://bsky.app/profile/redteamwrangler.bsky.social/post/3lxfh2jp65c2y)
* [The 'S' in MCP stands for "Security." I seriously do not understand how anyone looks at an MCP server in an enterprise security context and says "This will work. This meets my security requirements." Autonomous operation is diametrically opposed to control. 1/](https://bsky.app/profile/malwarejake.bsky.social/post/3lxfqrah36s2c)
* [WeTransfer says files not used to train AI after backlash, Jul 2025](https://www.bbc.com/news/articles/cp8mp79gyz1o), [As of today, we are dumping WeTransfer. The reason, an unacceptable crossing of ethical boundary lines. I encourage others to do the same and here's why... [...] Worse, when the backlash against this sneaky change became quite public, they furiously backpedalled, re-worded the clause and suggested they had made an error and reversed it. Lawyers have since looked at those changes and openly debated that it is arguably NOT a reversal at all; that they have simply made the language more vague to conceal the provision and leave the door open just enough for this still to go ahead.](https://www.linkedin.com/posts/darrenisaac_wetransfer-copyright-stealingip-activity-7363615657495543810-UnVo)
* [Did you know that LLMs fail at around 70% of all typical office tasks like generating a report on something from a spreadsheet? The Agent Company is a simulated office environment for benchmarking LLMs - I wrote a blog post about the paper here (with links and a rant): https://jilltxt.net/llms-fail-at-70-of-simple-office-tasks/](https://bsky.app/profile/jilltxt.bsky.social/post/3lxcm2l3k2c2b)
* [There is a wave of #AI bills sweeping Latin America üåä  We‚Äôve looked at the ones with most traction in 6 key jurisdictions - #Brazil, #Mexico, #Argentina, #Peru, #Chile, #Colombia, and found they have a lot in common! Including proposals for unacceptable risks. Enjoy! #AIlaw https://fpf.org/blog/global/ai-regulation-in-latin-america-overview-and-emerging-trends-in-key-proposals/](https://bsky.app/profile/gzf.bsky.social/post/3lwwayn4y522x)
* [Someone on Mastodon asked me my position on LLM-generated code. So let's get into it. üßµ /THREAD Sep 2025](https://bsky.app/profile/taggart-tech.com/post/3ly4j2bmbu22o)
* [Apple Open-Sources FastVLM and MobileCLIP2: A Revolutionary Breakthrough in AI Technology, Sep 2025. On-device AI revolution: No cloud, full privacy, instant results.](https://medium.com/@AdaGaoYY/apple-open-sources-fastvlm-and-mobileclip2-a-revolutionary-breakthrough-in-ai-technology-bb31e5d8c504)

Videos
* [This Horrifying 'Slaughterbot' Video Is The Best Warning Against Autonomous Weapons, Nov 2017](https://www.sciencealert.com/chilling-drone-video-shows-a-disturbing-vision-of-an-ai-controlled-future)
* [Microdrones: the AI assassins set to become weapons of mass destruction, Nov 2022](https://www.telegraph.co.uk/global-health/terror-and-security/drone-assassins-micro-killing-machine/)
* [As A.I.-Controlled Killer Drones Become Reality, Nations Debate Limits, Nov 2023](https://www.nytimes.com/2023/11/21/us/politics/ai-drones-war-law.html)
* [The existential horror of the paperclip factory. Oct 2024](https://www.youtube.com/watch?v=ZP7T6WAK3Ow) - French, English subtitles: Alignment, deception. https://www.securite-ia.fr/
* [Writing Doom ‚Äì Award-Winning Short Film on Superintelligence (2024), Oct 2024](https://www.youtube.com/watch?v=xfMQ7hzyFW4), https://futureoflife.org/project/superintelligence-imagined/
* [Background Remover lets you Remove Background from images and video using AI with a simple command line interface that is free and open source. ](https://github.com/nadermx/backgroundremover)
* [Bring your ideas to life.Gamma is your AI design partner for effortless presentations, websites, social media posts, and more‚Äîso you can focus on what you do best.](https://gamma.app)
* Tools: https://github.com/lllyasviel/FramePack, https://www.linkedin.com/posts/perrycarpenter_cybersecurity-securityawareness-ai-ugcPost-7318407774621548544-TJWP, https://github.com/hacksider/Deep-Live-Cam, https://magicam.ai/blog/2025/03/19/just-swap-face-magicams-voicechange-function-brings-you-the-most-perfect-deep-fake-experience/


Navigating 4 stages of Cloud Privacy for AI and ML Strategies, email+web
https://www.microsoft.com/en-us/security/blog/2021/12/09/best-practices-for-ai-security-risk-management/
https://github.com/mitre/advmlthreatmatrix
https://www.nist.gov/itl/ai-risk-management-framework
https://www.cisa.gov/news-events/alerts/2024/04/15/joint-guidance-deploying-ai-systems-securely
https://www.enisa.europa.eu/publications/cybersecurity-of-ai-and-standardisation
https://www.enisa.europa.eu/topics/iot-and-smart-infrastructures/artificial_intelligence/?tab=publications
https://www.forbes.com/councils/forbestechcouncil/2023/12/27/ai-in-security-policies-why-its-important-and-how-to-implement/
https://www.trendmicro.com/en_us/ciso/23/f/ai-cybersecurity-policy-considerations.html
https://blog.google/technology/safety-security/introducing-googles-secure-ai-framework/
https://owasp.org/www-project-top-10-for-large-language-model-applications/¬†
https://www.linkedin.com/posts/jalkove_enterprises-are-quickly-learning-that-ai-activity-7252738782158835714-RNV5?
    https://x.com/Benioff/status/1846985572553830850 "When you look at how Copilot has been delivered to customers, it‚Äôs disappointing. It just doesn‚Äôt work, and it doesn‚Äôt deliver any level of accuracy. Gartner says it‚Äôs spilling data everywhere, and customers are left cleaning up the mess. To add insult to injury, customers are then told to build their own custom LLMs. I have yet to find anyone who‚Äôs had a transformational experience with Microsoft Copilot or the pursuit of training and retraining custom LLMs. Copilot is more like Clippy 2.0.ü§∑‚Äç‚ôÇÔ∏è#AI #Microsoft #Copilot https://www.fastcompany.com/91208578/why-marc-benioff-is-all-in-on-ai-agentforce"
    https://x.com/Benioff/status/1848439092293275988 "Microsoft rebranding Copilot as ‚Äòagents‚Äô? That‚Äôs panic mode. Let‚Äôs be real‚ÄîCopilot‚Äôs a flop because Microsoft lacks the data, metadata, and enterprise security models to create real corporate intelligence. That is why Copilot is inaccurate, spills corporate data, and forces customers to build their own LLMs. Clippy 2.0, anyone? Meanwhile, Agentforce is transforming businesses now. Agentforce doesn‚Äôt just handle tasks‚Äîit autonomously drives sales, service, marketing, analytics, and commerce. With data, LLMs, workflows, and security all integrated into a single Customer 360 platform: This is what AI was meant to be. ‚ù§Ô∏èü§ñ #Agentforce #Customer360"
    https://huggingface.co/datasets/Salesforce/ContextualBench

AI Tokens/words limits: 512 to 4096, GPT4 32k, Claude2 100k, Gemini 1.5 Pro 1M
https://www.supernormal.com/blog/gpt-token-limits
https://www.linkedin.com/pulse/what-llm-token-limits-comparative-analysis-top-large-language-mohan
https://medium.com/@jaimonjk/how-can-large-token-limits-in-new-llm-models-transform-the-learning-and-development-function-5fc643c8df0d
https://www.bretcameron.com/blog/three-strategies-to-overcome-open-ai-token-limits

Security benchmarks
* [CyberSecEval 4Advancing the Evaluation of Cybersecurity Risks and Capabilities in Large Language Models](https://meta-llama.github.io/PurpleLlama/CyberSecEval/)
* [CTIBench: A Benchmark for Evaluating LLMs in Cyber Threat Intelligence, Jun 2024](https://arxiv.org/abs/2406.07599)
* [AI in the SOC: Benchmarking LLMs for Autonomous Alert Triage, Jun 2025](https://simbian.ai/blog/the-first-ai-soc-llm-benchmark) (vendor, lack details)


Detections
* [NOVA: The Prompt Pattern Matching](https://github.com/fr0gger/nova-framework/)

Courses
* [Stanford Webinar - Agentic AI: A Progression of Language Model Usage, Feb 2025](https://www.youtube.com/watch?v=kJLiOGle3Lw)
