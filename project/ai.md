Artificial Intelligence (AI) usage, policy & co

# AI/ML Governance Strategy
Define your purpose: trust, explainability, compliance...
Ask: What models are we building? Who owns the risks? What’s our stance on LLMs or autonomous systems?
Set your risk appetite and responsible AI principles.

# Policy

* own policy
* Acceptable Use Policy
* Data classification requirement
  * not for confidential+ data/suppose good classification but in practice, often global button
* Roles and Model Lifecycle Ownership

# Local or Cloud

# Incidents

# References

* Example policy: https://github.com/ThalesGroup/secure-ml/blob/main/security-policy/ml-secpol.md, https://github.com/ThalesGroup/secure-ml/blob/main/security-policy/ml-secpol-detailed.md

* [NIST AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework)
* [ISO/IEC 42001:2023 Information technology — Artificial intelligence — Management system](https://www.iso.org/standard/81230.html)
* [AI Risk Repository, MIT](https://airisk.mit.edu)
* [Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems, Jan 2024](https://arxiv.org/html/2401.05778v1)
* [Periodic Table of (Gen)AI Risks a quick reference, Feb 2025](https://www.linkedin.com/posts/iryna-schwindt-463a20158_every-day-we-see-hundreds-of-posts-highlighting-activity-7289375956509548544-7oBw)
* [AI Incident Database](https://incidentdatabase.ai/)
* [Global AI Regulation Tracker](https://www.techieray.com/GlobalAIRegulationTracker)
* https://www.sans.org/mlp/critical-ai-security-guidelines

News
* [Majority of firms using generative AI experience related security incidents – even as it empowers security teams, Nov 2024](https://www.itpro.com/technology/artificial-intelligence/majority-firms-using-generative-ai-related-security-incidents): "[Research](https://www.capgemini.com/insights/research-library/generative-ai-in-cybersecurity) by the Capgemini Research Institute found that 97% of organizations using generative AI were affected by data breaches or security concerns linked to generative AI. Over half (52%) pointed to direct and indirect losses of at least $50 million arising from these incidents. As a result, nearly six in ten (62%) said they needed to increase their budgets to mitigate the risks."
* [AI adoption in business is lagging really far behind the buzz. Only 5% of American companies actively use AI in their products, and for many startups, profitability is still a distant goal (if even reachable).](https://www.linkedin.com/feed/update/urn:li:activity:7264672924890984449/), [Will the bubble burst for AI in 2025, or will it start to deliver?It is the biggest gamble in business history—but adoption of AI is proving patchy, Nov 2024](https://www.economist.com/the-world-ahead/2024/11/18/will-the-bubble-burst-for-ai-in-2025-or-will-it-start-to-deliver)
* [The images of Spain’s floods weren’t created by AI. The trouble is, people think they were, Nov 2024](https://www.theguardian.com/commentisfree/2024/nov/09/the-images-of-spains-floods-werent-created-by-ai-the-trouble-is-people-think-they-were)
* [This can’t be real. While organizations are busy enforcing AI policies to protect confidential data, Microsoft quietly enables this by default and labels it ‘Your privacy matters.’ Unbelievable. Nov 2024](https://x.com/cyb3rops/status/1860604009767145776): "Heads up: Microsoft Office, like many companies in recent months, has slyly turned on an “opt-out” feature that scrapes your Word and Excel documents to train its internal AI systems. This setting is turned on by default, and you have to manually uncheck a box in order to opt out.  If you are a writer who uses MS Word to write any proprietary content (blog posts, novels, or any work you intend to protect with copyright and/or sell), you’re going to want to turn this feature off immediately."
* [German-French recommendations for the use of AI programming assistants, Oct 2024](https://www.bsi.bund.de/SharedDocs/Downloads/EN/BSI/KI/ANSSI_BSI_AI_Coding_Assistants.html), [L’ANSSI et le BSI publient leurs recommandations de sécurité concernant les assistants de programmation basés sur l’IA, Oct 2024](https://cyber.gouv.fr/actualites/lanssi-et-le-bsi-publient-leurs-recommandations-de-securite-concernant-les-assistants-de)
* [OpenAI’s transcription software, Whisper, “is prone to making up chunks of text or even entire sentences” of which “some of the invented text — known in the industry as hallucinations — can include racial commentary, violent rhetoric and even imagined medical treatments.”, Oct 2024](https://www.linkedin.com/feed/update/urn:li:activity:7256619287316967425/), https://www.pcmag.com/news/openais-whisper-experiencing-ai-hallucinations-despite-high-risk-applications
* [A great article in ACM on why humans and machines are different in terms of contextualization. They don’t even talk about consciousness. Nov 2024](https://www.linkedin.com/posts/pannala_the-context-problem-in-artificial-intelligence-activity-7265323181584900097-eeeV/), https://cacm.acm.org/opinion/the-context-problem-in-artificial-intelligence/
* [New Case Study in AI Risk Quantification: FAIR-AIR  Supporting Dissent in the FTC’s Rytr Case, Nov 2024](https://www.fairinstitute.org/blog/ai-risk-quantification-case-study-fair-air-ftc-rytr-case)
* [Industry trends Zero Trust 4 min read Agile Business, agile security: How AI and Zero Trust work together, Dec 2024](https://www.microsoft.com/en-us/security/blog/2024/12/16/agile-business-agile-security-how-ai-and-zero-trust-work-together/)
* [Fast vs. Slow AI, Jan 2025](https://danielmiessler.com/blog/fast-vs-slow-ai): We need to know when to use vs. refuse AI's speed
* [Implementing responsible AI in the generative age, Jan 2025](https://www.technologyreview.com/2025/01/22/1110043/implementing-responsible-ai-in-the-generative-age/) (report register-wall)
* [The Impact of Generative AI on Critical Thinking: Self-Reported Reductions in Cognitive Effort and Confidence Effects From a Survey of Knowledge Workers, Jan 2025](https://www.microsoft.com/en-us/research/uploads/prod/2025/01/lee_2025_ai_critical_thinking_survey.pdf), [GenAI is reshaping work—don’t let it dull human intelligence, Jan 2025](https://www.hfsresearch.com/research/genai-reshaping-work-intelligence/)
* [AI Cybersecurity Collaboration Playbook, Jan 2025](https://www.cisa.gov/resources-tools/resources/ai-cybersecurity-collaboration-playbook), [JCDC's AI Cybersecurity Playbook](lockboxx.blogspot.com/2025/01/jcdcs-ai-cybersecurity-playbook.html)
* [AI Copilot Code Quality: 2025 Look Back at 12 Months of Data, Feb 2025](https://www.gitclear.com/ai_assistant_code_quality_2025_research): Emerging trends: 4x more code cloning, "copy/paste" exceeds "moved" code for first time in history. Includes 2025 projections.
* [How to Steer AI Adoption: A CISO Guide, Feb 2025](https://thehackernews.com/2025/02/how-to-steer-ai-adoption-ciso-guide.html): CLEAR 5 steps, Create, Learn, Enforce, Apply, Reuse
* [Disrupting malicious uses of AI, Feb 2025](https://openai.com/global-affairs/disrupting-malicious-uses-of-ai/) - China, Visibility
* [Thomson Reuters Wins First Major AI Copyright Case in the US, Feb 2025](https://www.wired.com/story/thomson-reuters-ai-copyright-lawsuit/)
* [Microsoft’s Satya Nadella Pumps the Brakes on AI Hype, Feb 2025](https://gizmodo.com/microsofts-satya-nadella-pumps-the-breaks-on-ai-hype-2000566483)
* [AI Search Has A Citation Problem, Mar 2025](https://www.cjr.org/tow_center/we-compared-eight-ai-search-engines-theyre-all-bad-at-citing-news.php)
* [AI can steal your voice, and there's not much you can do about it, Mar 2025](https://www.nbcnews.com/tech/security/ai-voice-cloning-software-flimsy-guardrails-report-finds-rcna195131)
* [Klarna CEO doubts that other companies will replace Salesforce with AI, Mar 2025](https://techcrunch.com/2025/03/04/klarna-ceo-doubts-that-other-companies-will-replace-salesforce-with-ai/)
* [OpenAI declares AI race “over” if training on copyrighted works isn’t fair use, Mar 2025](https://arstechnica.com/tech-policy/2025/03/openai-urges-trump-either-settle-ai-copyright-debate-or-lose-ai-race-to-china/)
* [Anyone has Microsoft Security Copilot in place? Mar 2025](https://www.reddit.com/r/cybersecurity/comments/1jcw9x3/anyone_has_microsoft_security_copilot_in_place/)
* [AI project failure rates are on the rise: report. The share of businesses scrapping most of their AI initiatives increased to 42% this year, up from 17% last year, according to S&P Global Market Intelligence. Mar 2025](https://www.cybersecuritydive.com/news/AI-project-fail-data-SPGlobal/742768/)
* [Singapore authorities warn of rise in deepfake corporate video calls, Mar 2025](https://www.finextra.com/newsarticle/45645/singapore-authorities-warn-of-rise-in-deepfake-corporate-video-calls)
* [Study Finds That AI Search Engines Are Wrong an Astounding Proportion of the Time, Mar 2025](https://futurism.com/study-ai-search-wrong)
* [Implementation guide for managers of Artificial intelligence systems - ISDE Canada](https://ised-isde.canada.ca/site/ised/en/implementation-guide-managers-artificial-intelligence-systems)
* [CJEU Delivers Judgment on Automated Decision-Making, Mar 2025](https://www.griffinhouseconsultancy.co.uk/blog/cjeu-delivers-judgment-on-automated-decision-making/) - Schufa AG credit score, Case C-634-21
* [10 things you should include in your AI policy, Apr 2025](https://www.csoonline.com/article/3950176/10-things-you-should-include-in-your-ai-policy.html)
* [AI-hallucinated code dependencies become new supply chain risk, Apr 2025](https://www.bleepingcomputer.com/news/security/ai-hallucinated-code-dependencies-become-new-supply-chain-risk/)
* [AI 2027](https://ai-2027.com) AGI scenario
* [Professors Staffed a Fake Company Entirely With AI Agents, and You'll Never Guess What Happened, Apr 2025](https://futurism.com/professors-company-ai-agents), [Carnegie Mellon staffed a fake company with AI agents. It was a total disaster.](https://tech.yahoo.com/ai/articles/next-assignment-babysitting-ai-081502817.html?guccounter=1), https://the-agent-company.com/
* [OpenAI Stirs Controversy with GPT-4.1 Release Lacking Safety Report!, Apr 2025](https://opentools.ai/news/openai-stirs-controversy-with-gpt-41-release-lacking-safety-report)
* [New ChatGPT Models Seem to Leave Watermarks on Text, Apr 2025](https://www.rumidocs.com/newsroom/new-chatgpt-models-seem-to-leave-watermarks-on-text)
* [How to even get started with AI governance? Apr 2025](https://www.linkedin.com/posts/gregoryhaardt_how-to-even-get-started-with-ai-governance-activity-7319797388410265600-jq-t)
* [Superintelligent AgentsPose Catastrophic Risks:Can Scientist AI Offer aSafer Path? Yoshua Bengio, MILA, Apr 2025](https://indico.cern.ch/event/1522388/attachments/3044597/5380129/CERN-3apr2025.pdf)
* [CrowdStrike Research: Securing AI-Generated Code with Multiple Self-Learning AI Agents, Apr 2025](https://www.crowdstrike.com/en-us/blog/secure-ai-generated-code-with-multiple-self-learning-ai-agents/)
* [Reality Check](https://www.wheresyoured.at/reality-check/) - OpenAI Revenues
* [Time saved by AI offset by new work created, study suggests. Survey of 2023–2024 data finds that AI created more tasks for 8.4 percent of workers. May 2025](https://arstechnica.com/ai/2025/05/time-saved-by-ai-offset-by-new-work-created-study-suggests/)
* [Large Language Models are Unreliable for Cyber Threat Intelligence, Mar 2025](https://arxiv.org/abs/2503.23175)
* [Lessons from Defending Gemini Against Indirect Prompt Injections, May 2025](https://arxiv.org/abs/2505.14534v1)
* [This comes across as just a tiiiny little bit customer hostile. - Copilot](https://bsky.app/profile/getwired.com/post/3lpmraracqk2f)
* [Busting myths on Microsoft Security Copilot, May 2025](https://techcommunity.microsoft.com/blog/securitycopilotblog/busting-myths-on-microsoft-security-copilot/4414844)* [If you want an lol - Microsoft have implemented Copilot on its own GitHub repos and it’s a clusterfuck, you can see MS engineers publicly begging Copilot to work.www.reddit.com/r/Experience...](https://bsky.app/profile/GossiTheDog.cyberplace.social.ap.brid.gy/post/3lpor3uglie22), [My new hobby: watching AI slowly drive Microsoft employees insane, May 2025](https://www.reddit.com/r/ExperiencedDevs/comments/1krttqo/my_new_hobby_watching_ai_slowly_drive_microsoft/), [Allow us to block Copilot-generated issues (and PRs) from our own repositories #159749](https://github.com/orgs/community/discussions/159749)
* [Klarna decided it would lay off 700 of its workers and replace them with AI, with its CEO saying he would be “OpenAI’s guinea pig”.   He now says “..what you end up having is lower quality,”.. and goes on to say he’s realised customers expect to able to talk to a customer support agent.   So he’s come up with a genius recovery  plan - hire human workers he fired to replace the AI bots he installed.  https://finance.yahoo.com/news/firing-700-humans-ai-klarna-173029838.html, May 2025](https://bsky.app/profile/GossiTheDog.cyberplace.social.ap.brid.gy/post/3lpmc25gvtny2)
* [The 2025 AI Index Report, May 2025](https://hai.stanford.edu/ai-index/2025-ai-index-report)
* [This is interesting, the newer LLM models are getting worse, as this article and associated research paper at https://lnkd.in/et3XT8Cg demonstrate. May 2025](https://www.linkedin.com/posts/richardselfllm_this-is-interesting-the-newer-llm-models-activity-7330013445070741505-_6cj), [Generalization bias in large language model summarization of scientific research, Apr 2025](https://royalsocietypublishing.org/doi/10.1098/rsos.241776)
* [Take Nature’s AI research test: find out how your ethics compareWhat’s your view on using AI for peer review and for writing research papers? May 2025](https://www.nature.com/immersive/d41586-025-01512-2/index.html)
* [Widely covered MIT paper saying AI boosts worker productivity is, in fact, complete bullshit it turns out.](https://bsky.app/profile/GossiTheDog.cyberplace.social.ap.brid.gy/post/3lpdzkc3eomy2), https://www.wsj.com/tech/ai/mit-says-it-no-longer-stands-behind-students-ai-research-paper-11434092?st=sF3Wvo&reflink=desktopwebshare_permalink
* [A computer scientist’s perspective on vibe coding:](https://bsky.app/profile/garymarcus.bsky.social/post/3lpdgtvi7k22d), https://bsky.app/profile/qntm.org/post/3lpbv23rz622c
* [Should We Automate the CEO? TheHustle, Mar 2023](https://getpocket.com/explore/item/should-we-automate-the-ceo), HK NetDragon Websoft
* [Secret chatbot use causes workplace rifts, May 2025](https://www.axios.com/2025/05/29/secret-chatgpt-workplace)
* [A new report from Stanford finds that schools, parents, police, and our legal system are not prepared to deal with the growing problem of minors using AI to generate CSAM of other minors.🔗 https://www.404media.co/no-one-knows-how-to-deal-with-student-on-student-ai-csam/, May 2025](https://bsky.app/profile/404media.co/post/3lqcsi4tolk2l), https://cyber.fsi.stanford.edu/news/ai-csam-report
* [Duolingo's AI-First Disaster: A Cautionary Tale of What Happens When You Replace Rather Than Partner. Duolingo's 'AI-first' strategy backfired so badly they deleted all content from 6.7M TikTok and 4.1M Instagram accounts. The cautionary tale every CEO needs to read about replacing humans with AI. May 2025](https://www.groktop.us/duolingos-ai-first-disaster-a-cautionary-tale-of-what-happens-when-you-replace-rather-than-partner/)
* [shocked to hear that “...AI chatbots have had no significant impact on earnings or recorded hours in any occupation" based on a study of 25,000 workers at 7000 companies by the National Bureau of Economic Research, May 2025](https://bsky.app/profile/edzitron.com/post/3lpujcx324k2m), https://www.nber.org/papers/w33777, https://fortune.com/2025/05/18/ai-chatbots-study-impact-earnings-hours-worked-any-occupation/
* ["A database attempting to track the prevalence of the cases has identified 106 instances around the globe in which courts have found 'AI hallucinations' in court documents."](https://www.damiencharlotin.com/hallucinations/)
* [Anthropic’s new AI model turns to blackmail when engineers try to take it offline, May 2025](https://techcrunch.com/2025/05/22/anthropics-new-ai-model-turns-to-blackmail-when-engineers-try-to-take-it-offline/)
* [AI doomers and AI zoomers are two sides of the same coin, powered by a quasi-supernatural belief that God is coming to the machine. The reality is more mundane: that semi-functional AIs will thoroughly undermine the existing social order through myriad systems of abuse. Jun 2025](https://bsky.app/profile/joegalvin.bsky.social/post/3lqpf4e5g6s2m) - deepfake nudes
* [Generative AI in the Law School Classroom, Jun 2025](https://jeremysheff.com/2025/06/02/generative-ai-in-the-law-school-classroom/)
* [My AI Skeptic Friends Are All Nuts, Jun 2025](https://fly.io/blog/youre-all-nuts/)


Videos
* [This Horrifying 'Slaughterbot' Video Is The Best Warning Against Autonomous Weapons, Nov 2017](https://www.sciencealert.com/chilling-drone-video-shows-a-disturbing-vision-of-an-ai-controlled-future)
* [Microdrones: the AI assassins set to become weapons of mass destruction, Nov 2022](https://www.telegraph.co.uk/global-health/terror-and-security/drone-assassins-micro-killing-machine/)
* [As A.I.-Controlled Killer Drones Become Reality, Nations Debate Limits, Nov 2023](https://www.nytimes.com/2023/11/21/us/politics/ai-drones-war-law.html)
* [The existential horror of the paperclip factory. Oct 2024](https://www.youtube.com/watch?v=ZP7T6WAK3Ow) - French, English subtitles: Alignment, deception. https://www.securite-ia.fr/
* [Writing Doom – Award-Winning Short Film on Superintelligence (2024), Oct 2024](https://www.youtube.com/watch?v=xfMQ7hzyFW4), https://futureoflife.org/project/superintelligence-imagined/
* [Background Remover lets you Remove Background from images and video using AI with a simple command line interface that is free and open source. ](https://github.com/nadermx/backgroundremover)
* [Bring your ideas to life.Gamma is your AI design partner for effortless presentations, websites, social media posts, and more—so you can focus on what you do best.](https://gamma.app)
* Tools: https://github.com/lllyasviel/FramePack, https://www.linkedin.com/posts/perrycarpenter_cybersecurity-securityawareness-ai-ugcPost-7318407774621548544-TJWP, https://github.com/hacksider/Deep-Live-Cam, https://magicam.ai/blog/2025/03/19/just-swap-face-magicams-voicechange-function-brings-you-the-most-perfect-deep-fake-experience/


Navigating 4 stages of Cloud Privacy for AI and ML Strategies, email+web
https://www.microsoft.com/en-us/security/blog/2021/12/09/best-practices-for-ai-security-risk-management/
https://github.com/mitre/advmlthreatmatrix
https://www.nist.gov/itl/ai-risk-management-framework
https://www.cisa.gov/news-events/alerts/2024/04/15/joint-guidance-deploying-ai-systems-securely
https://www.enisa.europa.eu/publications/cybersecurity-of-ai-and-standardisation
https://www.enisa.europa.eu/topics/iot-and-smart-infrastructures/artificial_intelligence/?tab=publications
https://www.forbes.com/councils/forbestechcouncil/2023/12/27/ai-in-security-policies-why-its-important-and-how-to-implement/
https://www.trendmicro.com/en_us/ciso/23/f/ai-cybersecurity-policy-considerations.html
https://blog.google/technology/safety-security/introducing-googles-secure-ai-framework/
https://owasp.org/www-project-top-10-for-large-language-model-applications/ 
https://www.linkedin.com/posts/jalkove_enterprises-are-quickly-learning-that-ai-activity-7252738782158835714-RNV5?
    https://x.com/Benioff/status/1846985572553830850 "When you look at how Copilot has been delivered to customers, it’s disappointing. It just doesn’t work, and it doesn’t deliver any level of accuracy. Gartner says it’s spilling data everywhere, and customers are left cleaning up the mess. To add insult to injury, customers are then told to build their own custom LLMs. I have yet to find anyone who’s had a transformational experience with Microsoft Copilot or the pursuit of training and retraining custom LLMs. Copilot is more like Clippy 2.0.🤷‍♂️#AI #Microsoft #Copilot https://www.fastcompany.com/91208578/why-marc-benioff-is-all-in-on-ai-agentforce"
    https://x.com/Benioff/status/1848439092293275988 "Microsoft rebranding Copilot as ‘agents’? That’s panic mode. Let’s be real—Copilot’s a flop because Microsoft lacks the data, metadata, and enterprise security models to create real corporate intelligence. That is why Copilot is inaccurate, spills corporate data, and forces customers to build their own LLMs. Clippy 2.0, anyone? Meanwhile, Agentforce is transforming businesses now. Agentforce doesn’t just handle tasks—it autonomously drives sales, service, marketing, analytics, and commerce. With data, LLMs, workflows, and security all integrated into a single Customer 360 platform: This is what AI was meant to be. ❤️🤖 #Agentforce #Customer360"
    https://huggingface.co/datasets/Salesforce/ContextualBench

AI Tokens/words limits: 512 to 4096, GPT4 32k, Claude2 100k, Gemini 1.5 Pro 1M
https://www.supernormal.com/blog/gpt-token-limits
https://www.linkedin.com/pulse/what-llm-token-limits-comparative-analysis-top-large-language-mohan
https://medium.com/@jaimonjk/how-can-large-token-limits-in-new-llm-models-transform-the-learning-and-development-function-5fc643c8df0d
https://www.bretcameron.com/blog/three-strategies-to-overcome-open-ai-token-limits

Detections
* [NOVA: The Prompt Pattern Matching](https://github.com/fr0gger/nova-framework/)

Courses
* [Stanford Webinar - Agentic AI: A Progression of Language Model Usage, Feb 2025](https://www.youtube.com/watch?v=kJLiOGle3Lw)
